

#Load types - [CDC, FULL, INCREMENTAL, ADHOC, SNAPSHOT_D, SNAPSHOT_W, SNAPSHOT_M, ]

#audit_col is null in case of FULL load, in case of INCREMENTAL it will be created_at*, CDC->updated_at*
#partition_col will be null if not partitioned, if there is created_at, it will date(created_at,'YYYYMMDD') format will be used

dag: 'snapshots_db_replication'
nifi_url: 'http://localhost:8001/contentListener'

#src_db_af_conn_id: 'pgsql_150.24_merchant'

landing_bucket: 'mbk-nifi-landingzone' # Add this to particular table if you want to use diff landing_bucket for that table
data_path: 'data' # In this table extracted data will be stored. Add this to particular table if you want to use diff data_path for that table.
max_delta: 'maxdelta' #Location to store max_delta till which data has been extracted, This shoul be updated in metadata file
columns: '*' #column list in table if only particular columns needs to be extracted eg. columns:'memberid, txnid, createdat .. '
where: '1=1' #TODO check if this is necessary

#Config to be used for Glue Job
#glue_param_path:  's3://mbk-nifi-landingzone/Glue/' # not needed, will pass as a parameter directly
glue_job_name: '' #Common Glue job, If other job needs to be used, add in table params
target_bucket: 'mbk-datalake-common-prod'


tables:
    - snapshots_db_member_monthly:
        src_db_name: 'mobinew'
        src_table_name: 'member'
        load_type: 'SNAPSHOT_M'
        audit_col : 'updatedat'
        target_db_name: 'snapshots_db'
        target_table_name: 'member_monthly'
        primary_keys: 'id' #Comma separated values
        partition_col: 'day'
        partition_src_col: 'createdAt'
    - snapshots_db_member_weekly:
          src_db_name: 'mobinew'
          src_table_name: 'member'
          load_type: 'SNAPSHOT_W'
          audit_col: 'updatedat'
          target_db_name: 'snapshots_db'
          target_table_name: 'member_weekly'
          primary_keys: 'id' #Comma separated values
          partition_col: 'day'
          partition_src_col: 'createdAt'